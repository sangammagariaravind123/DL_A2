{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2wRn191Ke4iP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Config (change according to your dataset)\n",
        "LATIN_VOCAB_SIZE = 50\n",
        "DEVANAGARI_VOCAB_SIZE = 60\n",
        "EMBED_SIZE = 64\n",
        "HIDDEN_SIZE = 128\n",
        "\n",
        "# Encoder\n",
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embedding = layers.Embedding(vocab_size, embed_size)\n",
        "        self.gru = layers.GRU(hidden_size, return_state=True, return_sequences=True)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.embedding(x)\n",
        "        output, state = self.gru(x)\n",
        "        return state  # return final hidden state\n",
        "\n",
        "# Decoder\n",
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding = layers.Embedding(vocab_size, embed_size)\n",
        "        self.gru = layers.GRU(hidden_size, return_sequences=True, return_state=True)\n",
        "        self.fc = layers.Dense(vocab_size)\n",
        "\n",
        "    def call(self, x, hidden_state):\n",
        "        x = self.embedding(x)\n",
        "        output, state = self.gru(x, initial_state=hidden_state)\n",
        "        logits = self.fc(output)\n",
        "        return logits, state\n",
        "\n",
        "# Seq2Seq wrapper\n",
        "class Seq2Seq(tf.keras.Model):\n",
        "    def __init__(self, encoder, decoder, target_vocab_size):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.target_vocab_size = target_vocab_size\n",
        "\n",
        "    def call(self, src, tgt, training=False, teacher_forcing_ratio=0.5):\n",
        "        batch_size, tgt_len = tf.shape(tgt)[0], tf.shape(tgt)[1]\n",
        "        outputs = tf.TensorArray(tf.float32, size=tgt_len)\n",
        "\n",
        "        # Get encoder hidden state\n",
        "        encoder_hidden = self.encoder(src)\n",
        "\n",
        "        # First input to the decoder is the <sos> token\n",
        "        decoder_input = tf.expand_dims(tgt[:, 0], 1)  # shape (batch, 1)\n",
        "        hidden = encoder_hidden\n",
        "\n",
        "        for t in range(1, tgt_len):\n",
        "            preds, hidden = self.decoder(decoder_input, hidden)\n",
        "            preds = tf.squeeze(preds, axis=1)\n",
        "            outputs = outputs.write(t, preds)\n",
        "\n",
        "            # Teacher forcing\n",
        "            decoder_input = tf.expand_dims(\n",
        "                tgt[:, t] if tf.random.uniform([]) < teacher_forcing_ratio else tf.argmax(preds, axis=1),\n",
        "                1\n",
        "            )\n",
        "\n",
        "        return tf.transpose(outputs.stack(), [1, 0, 2])  # shape (batch, seq_len, vocab)\n",
        "\n",
        "# Instantiate\n",
        "encoder = Encoder(LATIN_VOCAB_SIZE, EMBED_SIZE, HIDDEN_SIZE)\n",
        "decoder = Decoder(DEVANAGARI_VOCAB_SIZE, EMBED_SIZE, HIDDEN_SIZE)\n",
        "seq2seq = Seq2Seq(encoder, decoder, DEVANAGARI_VOCAB_SIZE)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dummy data\n",
        "BATCH_SIZE = 32\n",
        "SRC_SEQ_LEN = 15\n",
        "TGT_SEQ_LEN = 20\n",
        "\n",
        "src = tf.random.uniform((BATCH_SIZE, SRC_SEQ_LEN), maxval=LATIN_VOCAB_SIZE, dtype=tf.int32)\n",
        "tgt = tf.random.uniform((BATCH_SIZE, TGT_SEQ_LEN), maxval=DEVANAGARI_VOCAB_SIZE, dtype=tf.int32)\n",
        "\n",
        "output = seq2seq(src, tgt, training=True)\n",
        "print(output.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMQ_LExBfZhc",
        "outputId": "db3498b1-f312-4da6-9b2b-96318f3b813b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 20, 60)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_indices = tf.argmax(output, axis=-1)  # shape: (32, 20)\n"
      ],
      "metadata": {
        "id": "nuPG-jI9jtzG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predicted_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OB9naVEmPn1",
        "outputId": "e5fbaafe-f287-490b-c20b-633bb7d836bc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 0 32 29 30 37 37 37 23 29 43  8 29 29 29 34 14 19  4 34 50]\n",
            " [ 0 49 25 58 35 25 42 56 58  2 22  8  8 43  8 25 58 51 22 44]\n",
            " [ 0 44 22  8 33  8 33  8 47 32 39 14 54 29 37 29 30 30 30 24]\n",
            " [ 0 30 36 37 37 37 37 37 37 56 32 50 25 53 37 32 50 14 40 14]\n",
            " [ 0 20 32 50 29 37 37 51 56 22  8 33 29 49 22  7  7  8 14  8]\n",
            " [ 0 19 25  2 53  7 53 51 56 22  8 33 30 37 37 37 37 43 31  2]\n",
            " [ 0 28 55  6 12 35 56 56  2 14 50 46 55 55  1 29 34 29 38 22]\n",
            " [ 0  0 43  8 33  8 33 54 29 37 37 37 19 40  9 40 31  7 13  7]\n",
            " [ 0 54  3  3 20 32 50 50  1  1 37 37  1 43  8 12 12 43 23  2]\n",
            " [ 0  0 42  0 43  8 12 29 18 35 56  5 45 32  0 12 12  4 22 22]\n",
            " [ 0 32 32 29 30 37 37 29 37 14 50 46 56 19 22 30 36  8 40 29]\n",
            " [ 0 28 55  6  6 35 56 33 49  8 29 30 38 18 22 58 14 46  7 38]\n",
            " [ 0 27 43  8 29 30 37 40 25 22  8 47 32 47 12 18 59 30  3  3]\n",
            " [ 0 27 43 35 42  0 43 32 50 29 37 37 56 50  1 29 30 18 30 30]\n",
            " [ 0 37 37 37 37 37 37 23 29 19 45 22 10 29 59 18 59 18 35 43]\n",
            " [ 0  7  7 46  8 47 12  8 33 49 11 32  1 29 50 37 37 37 33 37]\n",
            " [ 0 30 37 37 37 37 37 37 37 41 23 27 27 27 43 32 32 25 43 55]\n",
            " [ 0 52 40 25 53 40  9  9 49 30 37 37 37 25 58 27 43 29 43 55]\n",
            " [ 0 44 22 19 22  8 47 32 39  0 59 32 22  8  8 13  8 49 30 27]\n",
            " [ 0  1 37 37 37 37 37 43 51 24 38 38 27 27 43 43 35 51 51 51]\n",
            " [ 0  2  2 20 23 43 35 14 12 51 12 12 27 19 45 22  8 24 38 22]\n",
            " [ 0 43 54  3 54  3 50 45 29 29 37 37 57 30 37 47 12 55 51 44]\n",
            " [ 0 10 50  1 23 29 37 51 35 49 22  8 55  8 26 35 30 30 25 35]\n",
            " [ 0 19 32 39 41 23 27 43  8 43 35 42 21 35 56 59 32 43 42  8]\n",
            " [ 0 29 18 59 30 53 40 12 35  7 41 23  8 51 56 26 49 55 14 27]\n",
            " [ 0  6 35  6 35 56 32  1 23 23 29 34 51 53 37 53  7 12  7 51]\n",
            " [ 0 29  3 50 29 37 37 37 37 43 51 56 38 18 30 30 51 37  1  3]\n",
            " [ 0 45 22  8 29 30 37 37 37 37 37 37 49 24 22 22  8 12 18 51]\n",
            " [ 0 58 14 50 46 55 12 21 32 19 45 22 37 32 50 30 37 52 29 12]\n",
            " [ 0 42 29 18 59 43 53 35 30  0 59 32 32 23 27  8 29 29 30 14]\n",
            " [ 0 46 14 12 12 24 38 22 22 22  8 47 55  3 43  3 50 24 24 40]\n",
            " [ 0 25 58 27 43 35 42 32 29 32 28 52 31 29 37 58 35 29 29 30]], shape=(32, 20), dtype=int64)\n"
          ]
        }
      ]
    }
  ]
}